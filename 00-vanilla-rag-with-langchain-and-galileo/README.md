# Chatbot with LangChain, RAG, and Galileo

## üìö Contents

- [Overview](#overview)
- [Project Structure](#project-structure)
- [Setup](#setup)
- [Usage](#usage)
- [Contact & Support](#contact--support)

---

## üß† Overview

This project is an AI-powered chatbot built using **LangChain**, **RAG (Retrieval-Augmented Generation)**, and **Galileo** for model evaluation, protection, and observability. It leverages the **Z by HP AI Studio Local GenAI image** and the **LLaMA2-7B** model to generate contextual and document-grounded answers to user queries.

---

## üóÇ Project Structure

```
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ core
‚îÇ   ‚îî‚îÄ‚îÄ chatbot_service
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ chatbot_service.py
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îî‚îÄ‚îÄ AIStudioDoc.pdf
‚îú‚îÄ‚îÄ demo
‚îÇ   ‚îú‚îÄ‚îÄ assets
‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îî‚îÄ‚îÄ source
‚îú‚îÄ‚îÄ notebooks
‚îÇ   ‚îî‚îÄ‚îÄ chatbot-with-langchain.ipynb
‚îú‚îÄ‚îÄ configs
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml
‚îÇ   ‚îî‚îÄ‚îÄ secrets.yaml
‚îî‚îÄ‚îÄ requirements.txt
```

---

## ‚öôÔ∏è Setup

### Step 1: Create an AI Studio Project

- Create a new project in [Z by HP AI Studio](https://zdocs.datascience.hp.com/docs/aistudio/overview).
- (Optional) Add a description and relevant tags.

### Step 2: Set Up a Workspace

- Choose **Local GenAI** as the base image.

### Step 3: Clone the Repository

```bash
https://github.com/HPInc/aistudio-galileo-templates.git
```

- Ensure all files are available after workspace creation.

### Step 4: Add the Model to Workspace

- Download the **LLaMA2-7B** model from AWS S3:
  - **S3 URI**: `s3://149536453923-hpaistudio-public-assets/llama2-7b`
  - **Region**: `us-west-2`
- Make sure that the model in the `datafabric` folder inside your workspace.

### Step 5: Configure Secrets and Paths

- Add your API keys to the `secrets.yaml` file under the `configs` folder:
  - `HUGGINGFACE_API_KEY`
  - `GALILEO_API_KEY`
- Edit `config.yaml` with relevant configuration details.

---

## üöÄ Usage

### Step 1: Run the Notebook

Execute the notebook inside the `notebooks` folder:

```bash
notebooks/chatbot-with-langchain.ipynb
```

This will:

- Run the full RAG pipeline
- Integrate Galileo evaluation, protection, and observability
- Register the model in MLflow

### Step 2: Deploy the Chatbot Service

- Go to **Deployments > New Service** in AI Studio.
- Name the service and select the registered model.
- Choose a model version and enable **GPU acceleration**.
- Start the deployment.
- Once deployed, access the **Swagger UI** via the Service URL.
- From the Swagger page, click the demo link to interact with the locally deployed chatbot via UI.

---

## üìû Contact & Support

- üí¨ For issues or questions, please [open a GitHub issue](https://github.com/HPInc/aistudio-galileo-templates/issues).
- üìò Refer to the official [AI Studio Documentation](https://zdocs.datascience.hp.com/docs/aistudio/overview) for detailed instructions and troubleshooting tips.

---

> Built with ‚ù§Ô∏è using LangChain, Galileo, and Z by HP AI Studio.

