{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd9ff4be-1fee-47eb-8d09-611c29a7a83f",
   "metadata": {},
   "source": [
    "# Summarization of transcripts with Langchain\n",
    "\n",
    "In this example, we intend to create a summarizer for long transcripts. The main goal is to break the original transcript into different chunks based on context - i.e. using an unsupervised approach to identify the different topics throughout the transcript (somehow similarly to Topic Modelling) - and summarize each of these chunks. in the end, the different summaries are returned to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7156d10f-d930-4be7-a9e8-15606d466460",
   "metadata": {},
   "source": [
    "## Step 0: Configuring the environment\n",
    "\n",
    "Most of the libraries that are necessary for the development of this example are built-in on the GenAI workspace, available in AI Studio. More specific libraries to handle the type of input will be added here. In this case, we are giving support to transcripts in the webvtt format, used to store transcripts, which require the webvtt-py library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ca8fcd-58ec-4eb9-a9bc-8c93d632f284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webvtt-py in /opt/conda/lib/python3.12/site-packages (0.5.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: promptquality==0.64.2 in /opt/conda/lib/python3.12/site-packages (0.64.2)\n",
      "Requirement already satisfied: galileo-core<3.0.0,>=2.14.0 in /opt/conda/lib/python3.12/site-packages (from promptquality==0.64.2) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.25.0 in /opt/conda/lib/python3.12/site-packages (from promptquality==0.64.2) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.12/site-packages (from promptquality==0.64.2) (2.10.1)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.1.0 in /opt/conda/lib/python3.12/site-packages (from promptquality==0.64.2) (2.6.1)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.8.0 in /opt/conda/lib/python3.12/site-packages (from promptquality==0.64.2) (2.10.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /opt/conda/lib/python3.12/site-packages (from promptquality==0.64.2) (2.32.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in /opt/conda/lib/python3.12/site-packages (from promptquality==0.64.2) (4.67.0)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /opt/conda/lib/python3.12/site-packages (from galileo-core<3.0.0,>=2.14.0->promptquality==0.64.2) (0.27.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.12.2 in /opt/conda/lib/python3.12/site-packages (from galileo-core<3.0.0,>=2.14.0->promptquality==0.64.2) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->promptquality==0.64.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->promptquality==0.64.2) (2.27.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.1.0->promptquality==0.64.2) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->promptquality==0.64.2) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->promptquality==0.64.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->promptquality==0.64.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->promptquality==0.64.2) (2024.7.4)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->galileo-core<3.0.0,>=2.14.0->promptquality==0.64.2) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->galileo-core<3.0.0,>=2.14.0->promptquality==0.64.2) (1.0.7)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->galileo-core<3.0.0,>=2.14.0->promptquality==0.64.2) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->galileo-core<3.0.0,>=2.14.0->promptquality==0.64.2) (0.14.0)\n",
      "Requirement already satisfied: httpx==0.27.2 in /opt/conda/lib/python3.12/site-packages (0.27.2)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx==0.27.2) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx==0.27.2) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx==0.27.2) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.12/site-packages (from httpx==0.27.2) (3.10)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.12/site-packages (from httpx==0.27.2) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx==0.27.2) (0.14.0)\n",
      "Requirement already satisfied: galileo-protect==0.15.1 in /opt/conda/lib/python3.12/site-packages (0.15.1)\n",
      "Requirement already satisfied: galileo-core<3.0.0,>=2.17.0 in /opt/conda/lib/python3.12/site-packages (from galileo-protect==0.15.1) (2.23.0)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /opt/conda/lib/python3.12/site-packages (from galileo-core<3.0.0,>=2.17.0->galileo-protect==0.15.1) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.6.0 in /opt/conda/lib/python3.12/site-packages (from galileo-core<3.0.0,>=2.17.0->galileo-protect==0.15.1) (2.10.1)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.2.1 in /opt/conda/lib/python3.12/site-packages (from galileo-core<3.0.0,>=2.17.0->galileo-protect==0.15.1) (2.6.1)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.8.0 in /opt/conda/lib/python3.12/site-packages (from galileo-core<3.0.0,>=2.17.0->galileo-protect==0.15.1) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.12.2 in /opt/conda/lib/python3.12/site-packages (from galileo-core<3.0.0,>=2.17.0->galileo-protect==0.15.1) (4.12.2)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->galileo-core<3.0.0,>=2.17.0->galileo-protect==0.15.1) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->galileo-core<3.0.0,>=2.17.0->galileo-protect==0.15.1) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->galileo-core<3.0.0,>=2.17.0->galileo-protect==0.15.1) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->galileo-core<3.0.0,>=2.17.0->galileo-protect==0.15.1) (3.10)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->galileo-core<3.0.0,>=2.17.0->galileo-protect==0.15.1) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->galileo-core<3.0.0,>=2.17.0->galileo-protect==0.15.1) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.6.0->galileo-core<3.0.0,>=2.17.0->galileo-protect==0.15.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.6.0->galileo-core<3.0.0,>=2.17.0->galileo-protect==0.15.1) (2.27.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.2.1->galileo-core<3.0.0,>=2.17.0->galileo-protect==0.15.1) (1.0.1)\n",
      "Requirement already satisfied: galileo-observe==1.13.2 in /opt/conda/lib/python3.12/site-packages (1.13.2)\n",
      "Requirement already satisfied: galileo-core<3.0.0,>=2.20.0 in /opt/conda/lib/python3.12/site-packages (from galileo-observe==1.13.2) (2.23.0)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /opt/conda/lib/python3.12/site-packages (from galileo-observe==1.13.2) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /opt/conda/lib/python3.12/site-packages (from galileo-observe==1.13.2) (2.10.1)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.8.0 in /opt/conda/lib/python3.12/site-packages (from galileo-observe==1.13.2) (2.10.0)\n",
      "Requirement already satisfied: pytz<2025.0,>=2024.0 in /opt/conda/lib/python3.12/site-packages (from galileo-observe==1.13.2) (2024.2)\n",
      "Requirement already satisfied: tiktoken<0.9,>=0.7 in /opt/conda/lib/python3.12/site-packages (from galileo-observe==1.13.2) (0.8.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.2.1 in /opt/conda/lib/python3.12/site-packages (from galileo-core<3.0.0,>=2.20.0->galileo-observe==1.13.2) (2.6.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.12.2 in /opt/conda/lib/python3.12/site-packages (from galileo-core<3.0.0,>=2.20.0->galileo-observe==1.13.2) (4.12.2)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->galileo-observe==1.13.2) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->galileo-observe==1.13.2) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->galileo-observe==1.13.2) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->galileo-observe==1.13.2) (3.10)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->galileo-observe==1.13.2) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->galileo-observe==1.13.2) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->galileo-observe==1.13.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->galileo-observe==1.13.2) (2.27.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.12/site-packages (from tiktoken<0.9,>=0.7->galileo-observe==1.13.2) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.12/site-packages (from tiktoken<0.9,>=0.7->galileo-observe==1.13.2) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.2.1->galileo-core<3.0.0,>=2.20.0->galileo-observe==1.13.2) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<0.9,>=0.7->galileo-observe==1.13.2) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<0.9,>=0.7->galileo-observe==1.13.2) (2.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install webvtt-py\n",
    "!pip install pandas\n",
    "!pip install promptquality==0.64.2\n",
    "!pip install httpx==0.27.2\n",
    "!pip install galileo-protect==0.15.1\n",
    "!pip install galileo-observe==1.13.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ff65e3-dbdf-457a-8746-66c453182f26",
   "metadata": {},
   "source": [
    "### Configuration of Hugging face caches\n",
    "\n",
    "In the next cell, we configure HuggingFace cache, so that all the models downloaded from them are persisted locally, even after the workspace is closed. This is a future desired feature for AI Studio and the GenAI addon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "713a24f4-01f4-4a33-8124-7d7601ced6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"/home/jovyan/local/hugging_face\"\n",
    "os.environ[\"HF_HUB_CACHE\"] = \"/home/jovyan/local/hugging_face/hub\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d92659e-23ea-4965-bb27-58cd1dd0f3ec",
   "metadata": {},
   "source": [
    "## Step 1: Loading the data from the transcript\n",
    "\n",
    "At first, we need to read the data from the transcript. As our transcript is in the .vtt format, we use a library called webvtt-py to read the content. As the text is a trancript of audio/video, it is organized in small chunks of conversation, each containing a sequential id, the time of the start and end of the chunk, and the text content (often in the form speaker:content).\n",
    "\n",
    "From this data, we expect to extract the actual content,  while keeping reference to the other metadata - for this reason, we are loading all the data into a Pandas dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc16a213-9f92-4c75-93ff-66adc3133cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>content</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>I am happy to join with you today</td>\n",
       "      <td>00:00:00.880</td>\n",
       "      <td>00:00:03.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>in what will go down in history</td>\n",
       "      <td>00:00:06.500</td>\n",
       "      <td>00:00:09.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>as the greatest demonstration for freedom in t...</td>\n",
       "      <td>00:00:11.720</td>\n",
       "      <td>00:00:16.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>nation.</td>\n",
       "      <td>00:00:16.460</td>\n",
       "      <td>00:00:17.293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>Five score years ago,</td>\n",
       "      <td>00:00:26.410</td>\n",
       "      <td>00:00:28.740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id speaker                                            content         start  \\\n",
       "0  1                          I am happy to join with you today  00:00:00.880   \n",
       "1  2                            in what will go down in history  00:00:06.500   \n",
       "2  3          as the greatest demonstration for freedom in t...  00:00:11.720   \n",
       "3  4                                                    nation.  00:00:16.460   \n",
       "4  5                                      Five score years ago,  00:00:26.410   \n",
       "\n",
       "            end  \n",
       "0  00:00:03.920  \n",
       "1  00:00:09.360  \n",
       "2  00:00:16.460  \n",
       "3  00:00:17.293  \n",
       "4  00:00:28.740  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webvtt\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"id\": [],\n",
    "    \"speaker\": [],\n",
    "    \"content\": [],\n",
    "    \"start\": [],\n",
    "    \"end\": []\n",
    "}\n",
    "\n",
    "for caption in webvtt.read('data/I_have_a_dream.vtt'):\n",
    "    line = caption.text.split(\":\")\n",
    "    while len(line) < 2:\n",
    "        line = [''] + line\n",
    "    data[\"id\"].append(caption.identifier)\n",
    "    data[\"speaker\"].append(line[0].strip())\n",
    "    data[\"content\"].append(line[1].strip())\n",
    "    data[\"start\"].append(caption.start)\n",
    "    data[\"end\"].append(caption.end)\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.head()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbb6763-3eb0-41fb-900f-67778c3d5caf",
   "metadata": {},
   "source": [
    "As a second option, we provide here a code to load the same structure from a plain text document, which only contains the actual content of the speech/conversation, without extra metadata. For the sake of simplicity and reuse of code, we keep the same Data Frame structure as the previous version, by filling the remaining fields with empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1b33cbb-1c2b-404e-ad65-b243c6702308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>content</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>I am happy to join with you today in what will...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Five score years ago, a great American, in who...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>One hundred years later, the colored American ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>In a sense we have come to our Nation’s Capita...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>This note was a promise that all men, yes, bla...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id speaker                                            content start end\n",
       "0             I am happy to join with you today in what will...          \n",
       "1             Five score years ago, a great American, in who...          \n",
       "2             One hundred years later, the colored American ...          \n",
       "3             In a sense we have come to our Nation’s Capita...          \n",
       "4             This note was a promise that all men, yes, bla...          "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open(\"data/I_have_a_dream.txt\") as file:\n",
    "    lines = file.read()\n",
    "\n",
    "data = {\n",
    "    \"id\": [],\n",
    "    \"speaker\": [],\n",
    "    \"content\": [],\n",
    "    \"start\": [],\n",
    "    \"end\": []\n",
    "}\n",
    "\n",
    "for line in lines.split(\"\\n\"):\n",
    "    if line.strip() != \"\":\n",
    "        data[\"id\"].append(\"\")\n",
    "        data[\"speaker\"].append(\"\")\n",
    "        data[\"content\"].append(line.strip())\n",
    "        data[\"start\"].append(\"\")\n",
    "        data[\"end\"].append(\"\")        \n",
    "        \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416e122c-5a54-4285-8788-be12fc86e278",
   "metadata": {},
   "source": [
    "## Step 2: Semantic chunking of the transcript\n",
    "Having the information content loaded according to the transcription format - with the text split into audio blocks, or into paragraphs, we now want to group these small blocks into relevant topics - so we can summarize each topic individually. Here, we are using a very simple approach for that, by using a semantic embedding of each sentence (using an embedding model from Hugging Face Sentence Transformers), and identifying the \"breaks\" among chunks as the ones with higher semantic distance. Notice that this method can be parameterized, to inform the number of topics or the best method to identify the breaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62c67feb-11f7-47ad-bdec-3ec252e51797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = embedding_model.encode(df.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5538aee-0233-4b58-a574-879dfa64a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticSplitter():\n",
    "    def __init__ (self, content, embedding_model, method=\"number\", partition_count = 10, quantile = 0.9):\n",
    "        self.content = content\n",
    "        self.embedding_model = embedding_model\n",
    "        self.partition_count = partition_count\n",
    "        self.quantile = quantile\n",
    "        self.embeddings = embedding_model.encode(content)\n",
    "        self.distances = [cosine(embeddings[i - 1], embeddings[i]) for i in range(1, len(embeddings))]\n",
    "        self.breaks = []\n",
    "        self.centroids = []\n",
    "        self.load_breaks(method=method)\n",
    "\n",
    "    def centroid_distance(self, embedding_id, centroid_id):\n",
    "        return cosine(self.embeddings[embedding], self.centroid[centroid])\n",
    "\n",
    "    def adjust_neighbors(self):\n",
    "        self.breaks = []\n",
    "\n",
    "    def load_breaks(self, method = 'number'):\n",
    "        if method == 'number':\n",
    "            if self.partition_count > len(self.distances):\n",
    "                self.partition_count = len(self.distances)\n",
    "            self.breaks = np.sort(np.argpartition(self.distances, self.partition_count - 1)[0:self.partition_count - 1])\n",
    "        elif method == 'quantiles':\n",
    "            threshold = np.quantile(self.distances, self.quantile)\n",
    "            self.breaks = [i for i, v in enumerate(self.distances) if v >= threshold]\n",
    "        else:\n",
    "            self.breaks = []\n",
    "\n",
    "    def get_centroid(self, beginning, end):\n",
    "        return embedding_model.encode('\\n'.join(self.content[beginning : end]))\n",
    "    \n",
    "    def load_centroids(self):\n",
    "        if len(self.breaks) == 0:\n",
    "            self.centroids = [self.get_centroid(0, len(self.content))]\n",
    "        else:\n",
    "            self.centroids = []\n",
    "            beginning = 0\n",
    "            for break_position in self.breaks:\n",
    "                self.centroids += [self.get_centroid(beginning, break_position + 1)]\n",
    "                beginning = break_position + 1\n",
    "            self.centroids += [self.get_centroid(beginning, len(self.content))]\n",
    "\n",
    "    def get_chunk(self, beginning, end):\n",
    "        return '\\n'.join(self.content[beginning : end])\n",
    "    \n",
    "    def get_chunks(self):\n",
    "        if len(self.breaks) == 0:\n",
    "            return [self.get_chunk(0, len(self.content))]\n",
    "        else:\n",
    "            chunks = []\n",
    "            beginning = 0\n",
    "            for break_position in self.breaks:\n",
    "                chunks += [self.get_chunk(beginning, break_position + 1)]\n",
    "                beginning = break_position + 1\n",
    "            chunks += [self.get_chunk(beginning, len(self.content))]\n",
    "        return chunks\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01f13a0c-9704-462c-ba20-6b267367648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_separator = \"\\n *-* \\n\"\n",
    "\n",
    "splitter = SemanticSplitter(df.content, embedding_model, method=\"number\", partition_count=6)\n",
    "chunks = chunk_separator.join(splitter.get_chunks())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc63ed05-192e-4f59-856c-cf9bff160fc8",
   "metadata": {},
   "source": [
    "## Step 3: Using a LLM model to Summarize each chunk\n",
    "In our example, we are going to summarize each individual chunk separately. This solution might be advantageous in different situations:\n",
    " * When the original text is too big , or the loaded model works with a context that is too small. In this scenario, breaking information into chunks are necessary to allow the model to be applied\n",
    " * When the user wants to make sure that all the separate topics of a conversation are covered into the summarized version. An extra step could be added to allow some verification or manual configuration of the chunks to allow the user to customize the output\n",
    "\n",
    "To achieve this goal, we load a LLM model and use a summarization prompt. For the model, we illustrate four different options here:\n",
    "* Calling an cloud API (e.g. openAI API): This would require an API key from the desired service. In our example, we reccomend saving your API keys into a secrets.yaml file, and not shared together with the code, for security issues. An example with empty keys is provided with our code\n",
    "* Connecting to a Hugging Face rest API: This also requires an API key\n",
    "* Loading the model locally using Hugging Face repo: This would require to download the model in the first time you run your code. This might take several minutes (depending on your internet connection), and the model will be saved in local HF cache (set to be persisted in the beginning of this notebook)\n",
    "* Loading the model from a file available as a project asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d289f610-c5a2-49ad-860d-4ec2068fcaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code to access model through OpenAI service\n",
    "\n",
    "import os\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "import yaml\n",
    "with open('secrets.yaml') as file:\n",
    "    secrets = yaml.safe_load(file)\n",
    "os.environ[\"OPENAI_API_KEY\"] = secrets[\"OpenAI\"]\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b80dd01-5200-4690-a323-14b5e4acd0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Alternate code to connect to Hugging Face models\n",
    "#from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "#import yaml\n",
    "#with open('secrets.yaml') as file:\n",
    "#    secrets = yaml.safe_load(file)\n",
    "#huggingfacehub_api_token = secrets[\"HuggingFace\"]\n",
    "\n",
    "#repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "#llm = HuggingFaceEndpoint(\n",
    "#   huggingfacehub_api_token=huggingfacehub_api_token,\n",
    "#   repo_id=repo_id,\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6fb7e0-75db-4166-93f3-bd3d9ff547fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_huggingface import HuggingFacePipeline\n",
    "#from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "#model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "#model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "#pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=100, device=0)\n",
    "#llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62518d5a-8321-4c17-ba61-7f8960f4545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Alternate code to load local models. \n",
    "###This specific example requires the project to have an asset call Llama7b, associated with the cloud S3 URI s3://dsp-demo-bucket/LLMs (public bucket)\n",
    "\n",
    "#from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "#from langchain_community.llms import LlamaCpp\n",
    "\n",
    "#callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "\n",
    "#llm = LlamaCpp(\n",
    "            #model_path=\"/home/jovyan/datafabric/Llama7b/ggml-model-f16-Q5_K_M.gguf\",\n",
    "            #n_gpu_layers=64,\n",
    "            #n_batch=512,\n",
    "            #n_ctx=4096,\n",
    "            #max_tokens=1024,\n",
    "            #f16_kv=True,  \n",
    "            #callback_manager=callback_manager,\n",
    "            #verbose=False,\n",
    "            #stop=[],\n",
    "            #streaming=False,\n",
    "            #temperature=0.4,\n",
    "        #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "043cdb8f-a70a-499a-a2d6-56c14d965169",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = '''\n",
    "The following text is an excerpt of a transcription:\n",
    "\n",
    "### \n",
    "{context} \n",
    "###\n",
    "\n",
    "Please, produce a single paragraph summarizing the given excerpt.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a586d-fbf5-4551-b022-d50da386e74c",
   "metadata": {},
   "source": [
    "## Step 4: Create parallel chain to summarize the transcript\n",
    "\n",
    "In the following cell, we create a chain that will receive a single string with multiple chunks (separated by the declared separator), than:\n",
    "  * Break the input into separated chains - using the break_chunks function embedded in a RunnableLambda to be used in LangChain\n",
    "  * Run a Parallel Chain with the following elements for each chunk:\n",
    "    * Get an individual element\n",
    "    * Personalize the prompt template to create an individual prompt for each chunk\n",
    "    * Use the LLM inference to summarize the chunk\n",
    "  * Merge the individual summaries into a single one\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40e5cde3-b064-4280-8ada-8df68820a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "\n",
    "def join_summaries(summaries):\n",
    "    return \"\\n\".join(list(summaries.values()))\n",
    "\n",
    "def break_chunks(chunks):\n",
    "    return chunks.split(chunk_separator)\n",
    "\n",
    "lambda_join = RunnableLambda(join_summaries)\n",
    "lambda_break = RunnableLambda(break_chunks)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "chain = lambda_break | {f\"summary_{i}\" : itemgetter(i) | prompt | llm  for (i, _) in enumerate(RunnablePassthrough())} | lambda_join | StrOutputParser()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7d2a5d-35e3-46ed-a53e-ef49fc1c11a4",
   "metadata": {},
   "source": [
    "## Step 5: Connect to Galileo\n",
    "Through the Galileo library called Prompt Quality, we connect our API generated in the Galileo console to log in. To get your ApiKey, use this link: https://console.hp.galileocloud.io/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7e666a9-311c-42d4-bc34-260333184ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👋 You have logged into 🔭 Galileo (https://console.hp.galileocloud.io/) as diogo.vieira@hp.com.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Config(console_url=HttpUrl('https://console.hp.galileocloud.io/'), username=None, password=None, api_key=SecretStr('**********'), token=SecretStr('**********'), current_user='diogo.vieira@hp.com', current_project_id=None, current_project_name=None, current_run_id=None, current_run_name=None, current_run_url=None, current_run_task_type=None, current_template_id=None, current_template_name=None, current_template_version_id=None, current_template_version=None, current_template=None, current_dataset_id=None, current_job_id=None, current_prompt_optimization_job_id=None, api_url=HttpUrl('https://api.hp.galileocloud.io/'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import promptquality as pq\n",
    "\n",
    "import yaml\n",
    "with open('secrets.yaml') as file:\n",
    "    secrets = yaml.safe_load(file)\n",
    "os.environ['GALILEO_API_KEY'] = secrets[\"Galileo\"]\n",
    "galileo_url = \"https://console.hp.galileocloud.io/\"\n",
    "pq.login(galileo_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10d47fe-41b9-4f19-9b11-4ef2d3f2740f",
   "metadata": {},
   "source": [
    "## Step 6: Run the chain and connect the metrics to Galileo\n",
    "\n",
    "In this session, we call the created chain and create the mechanisms to ingest the quality metrics into Galileo. For this example, we create a personalized metric (scorer), that will be running locally to measure the quality of the summarization. For this reason, we use HuggingFace implementation of ROUGE (using evaluate library), and implement into a CustomScorer from Galileo (next cell).\n",
    "\n",
    "Below, we illustrate two alternative ways to connect to Galileo:\n",
    "  * Using a customized run, which calculates the scores and logs into Galileo\n",
    "  * Using the langchain callback (currently unavailable due to compatibility issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c27bb40e-7823-490a-af94-0d8aae5e5886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking the chain...\n",
      "Response returned by the chain: \n",
      "In this excerpt from a speech, the speaker discusses the continued struggles of African Americans despite the Emancipation Proclamation and the promise of equality in the Constitution. They call for immediate action and remind the audience that the fight for equality is ongoing. The speaker also shares their dream of a future where all people are judged by their character rather than the color of their skin.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac735638252749d1ad045610aab8581a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing chain run...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial job complete, executing scorers asynchronously. Current status:\n",
      "cost: Done ✅\n",
      "toxicity: Done ✅\n",
      "sexist: Done ✅\n",
      "pii: Done ✅\n",
      "protect_status: Done ✅\n",
      "latency: Done ✅\n",
      "🔭 View your prompt run on the Galileo console at: https://console.hp.galileocloud.io/prompt/chains/aa1fac84-a853-4f23-9a3b-41fc87759c1e/7fa8122b-a54d-4e11-8bbc-7e7d4a7b4d77?taskType=12\n",
      "node_input: I am happy to join with you today in what will go down in history as the greatest demonstration for freedom in the history of our nation.\n",
      "Five score years ago, a great American, in whose symbolic shadow we stand today, signed the Emancipation Proclamation. This momentous decree came as a great beacon of hope to millions of slaves, who had been seared in the flames of whithering injustice. It came as a joyous daybreak to end the long night of their captivity. But one hundred years later, the colored America is still not free. One hundred years later, the life of the colored American is still sadly crippled by the manacle of segregation and the chains of discrimination.\n",
      "One hundred years later, the colored American lives on a lonely island of poverty in the midst of a vast ocean of material prosperity. One hundred years later, the colored American is still languishing in the corners of American society and finds himself an exile in his own land So we have come here today to dramatize a shameful condition.\n",
      "In a sense we have come to our Nation’s Capital to cash a check. When the architects of our great republic wrote the magnificent words of the Constitution and the Declaration of Independence, they were signing a promissory note to which every American was to fall heir.\n",
      "This note was a promise that all men, yes, black men as well as white men, would be guaranteed the inalienable rights of life liberty and the pursuit of happiness.\n",
      "It is obvious today that America has defaulted on this promissory note insofar as her citizens of color are concerned. Instead of honoring this sacred obligation, America has given its colored people a bad check, a check that has come back marked “insufficient funds.”\n",
      "But we refuse to believe that the bank of justice is bankrupt. We refuse to believe that there are insufficient funds in the great vaults of opportunity of this nation. So we have come to cash this check, a check that will give us upon demand the riches of freedom and security of justice.\n",
      "We have also come to his hallowed spot to remind America of the fierce urgency of Now. This is not time to engage in the luxury of cooling off or to take the tranquilizing drug of gradualism.\n",
      "Now is the time to make real the promise of democracy.\n",
      "Now it the time to rise from the dark and desolate valley of segregation to the sunlit path of racial justice.\n",
      "Now it the time to lift our nation from the quicksand of racial injustice to the solid rock of brotherhood.\n",
      "Now is the time to make justice a reality to all of God’s children.\n",
      "I would be fatal for the nation to overlook the urgency of the moment and to underestimate the determination of it’s colored citizens. This sweltering summer of the colored people’s legitimate discontent will not pass until there is an invigorating autumn of freedom and equality. Nineteen sixty-three is not an end but a beginning. Those who hope that the colored Americans needed to blow off steam and will now be content will have a rude awakening if the nation returns to business as usual.\n",
      "There will be neither rest nor tranquility in America until the colored citizen is granted his citizenship rights. The whirlwinds of revolt will continue to shake the foundations of our nation until the bright day of justice emerges.\n",
      "We can never be satisfied as long as our bodies, heavy with the fatigue of travel, cannot gain lodging in the motels of the highways and the hotels of the cities.\n",
      "We cannot be satisfied as long as the colored person’s basic mobility is from a smaller ghetto to a larger one.\n",
      "We can never be satisfied as long as our children are stripped of their selfhood and robbed of their dignity by signs stating “for white only.”\n",
      "We cannot be satisfied as long as a colored person in Mississippi cannot vote and a colored person in New York believes he has nothing for which to vote.\n",
      "No, no we are not satisfied and we will not be satisfied until justice rolls down like waters and righteousness like a mighty stream.\n",
      "I am not unmindful that some of you have come here out of your trials and tribulations. Some of you have come from areas where your quest for freedom left you battered by storms of persecutions and staggered by the winds of police brutality.\n",
      "You have been the veterans of creative suffering. Continue to work with the faith that unearned suffering is redemptive.\n",
      "Go back to Mississippi, go back to Alabama, go back to South Carolina go back to Georgia, go back to Louisiana, go back to the slums and ghettos of our modern cities, knowing that somehow this situation can and will be changed.\n",
      "Let us not wallow in the valley of despair. I say to you, my friends, we have the difficulties of today and tomorrow.\n",
      "I still have a dream. It is a dream deeply rooted in the American dream.\n",
      "I have a dream that one day this nation will rise up and live out the true meaning of its creed. We hold these truths to be self-evident that all men are created equal.\n",
      "I have a dream that one day out in the red hills of Georgia the sons of former slaves and the sons of former slaveowners will be able to sit down together at the table of brotherhood.\n",
      "I have a dream that one day even the state of Mississippi, a state sweltering with the heat of oppression, will be transformed into an oasis of freedom and justice.\n",
      "I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by their character.\n",
      "I have a dream today.\n",
      "I have a dream that one day down in Alabama, with its vicious racists, with its governor having his lips dripping with the words of interposition and nullification; that one day right down in Alabama little black boys and black girls will be able to join hands with little white boys and white girls as sisters and brothers.\n",
      "I have a dream today.\n",
      " *-* \n",
      "I have a dream that one day every valley shall be engulfed, every hill shall be exalted and every mountain shall be made low, the rough places will be made plains and the crooked places will be made straight and the glory of the Lord shall be revealed and all flesh shall see it together.\n",
      "This is our hope. This is the faith that I will go back to the South with. With this faith we will be able to hew out of the mountain of despair a stone of hope.\n",
      "With this faith we will be able to transform the jangling discords of our nation into a beautiful symphony of brotherhood.\n",
      "With this faith we will be able to work together, to pray together, to struggle together, to go to jail together, to climb up for freedom together, knowing that we will be free one day.\n",
      "This will be the day when all of God’s children will be able to sing with new meaning “My country ’tis of thee, sweet land of liberty, of thee I sing. Land where my father’s died, land of the Pilgrim’s pride, from every mountainside, let freedom ring!”\n",
      "And if America is to be a great nation, this must become true. So let freedom ring from the hilltops of New Hampshire. Let freedom ring from the mighty mountains of New York.\n",
      " *-* \n",
      "Let freedom ring from the heightening Alleghenies of Pennsylvania.\n",
      " *-* \n",
      "Let freedom ring from the snow-capped Rockies of Colorado.\n",
      " *-* \n",
      "Let freedom ring from the curvaceous slopes of California.\n",
      "But not only that, let freedom, ring from Stone Mountain of Georgia.\n",
      " *-* \n",
      "Let freedom ring from every hill and molehill of Mississippi and every mountainside.\n",
      "When we let freedom ring, when we let it ring from every tenement and every hamlet, from every state and every city, we will be able to speed up that day when all of God’s children, black men and white men, Jews and Gentiles, Protestants and Catholics, will be able to join hands and sing in the words of the old spiritual, “Free at last, free at last. Thank God Almighty, we are free at last.”\n",
      "node_output: \n",
      "In this excerpt from a speech, the speaker discusses the ongoing struggle for freedom and equality for African Americans, citing the Emancipation Proclamation and the promise of the Constitution. They call for immediate action and emphasize the urgency of the situation, stating that there can be no rest until justice is achieved. The speaker also shares their dream for a future where all races can coexist peacefully and where people are judged by their character rather than the color of their skin.\n",
      "Error decoding JSON in node_input: I am happy to join with you today in what will go down in history as the greatest demonstration for freedom in the history of our nation.\n",
      "Five score years ago, a great American, in whose symbolic shadow we stand today, signed the Emancipation Proclamation. This momentous decree came as a great beacon of hope to millions of slaves, who had been seared in the flames of whithering injustice. It came as a joyous daybreak to end the long night of their captivity. But one hundred years later, the colored America is still not free. One hundred years later, the life of the colored American is still sadly crippled by the manacle of segregation and the chains of discrimination.\n",
      "One hundred years later, the colored American lives on a lonely island of poverty in the midst of a vast ocean of material prosperity. One hundred years later, the colored American is still languishing in the corners of American society and finds himself an exile in his own land So we have come here today to dramatize a shameful condition.\n",
      "In a sense we have come to our Nation’s Capital to cash a check. When the architects of our great republic wrote the magnificent words of the Constitution and the Declaration of Independence, they were signing a promissory note to which every American was to fall heir.\n",
      "This note was a promise that all men, yes, black men as well as white men, would be guaranteed the inalienable rights of life liberty and the pursuit of happiness.\n",
      "It is obvious today that America has defaulted on this promissory note insofar as her citizens of color are concerned. Instead of honoring this sacred obligation, America has given its colored people a bad check, a check that has come back marked “insufficient funds.”\n",
      "But we refuse to believe that the bank of justice is bankrupt. We refuse to believe that there are insufficient funds in the great vaults of opportunity of this nation. So we have come to cash this check, a check that will give us upon demand the riches of freedom and security of justice.\n",
      "We have also come to his hallowed spot to remind America of the fierce urgency of Now. This is not time to engage in the luxury of cooling off or to take the tranquilizing drug of gradualism.\n",
      "Now is the time to make real the promise of democracy.\n",
      "Now it the time to rise from the dark and desolate valley of segregation to the sunlit path of racial justice.\n",
      "Now it the time to lift our nation from the quicksand of racial injustice to the solid rock of brotherhood.\n",
      "Now is the time to make justice a reality to all of God’s children.\n",
      "I would be fatal for the nation to overlook the urgency of the moment and to underestimate the determination of it’s colored citizens. This sweltering summer of the colored people’s legitimate discontent will not pass until there is an invigorating autumn of freedom and equality. Nineteen sixty-three is not an end but a beginning. Those who hope that the colored Americans needed to blow off steam and will now be content will have a rude awakening if the nation returns to business as usual.\n",
      "There will be neither rest nor tranquility in America until the colored citizen is granted his citizenship rights. The whirlwinds of revolt will continue to shake the foundations of our nation until the bright day of justice emerges.\n",
      "We can never be satisfied as long as our bodies, heavy with the fatigue of travel, cannot gain lodging in the motels of the highways and the hotels of the cities.\n",
      "We cannot be satisfied as long as the colored person’s basic mobility is from a smaller ghetto to a larger one.\n",
      "We can never be satisfied as long as our children are stripped of their selfhood and robbed of their dignity by signs stating “for white only.”\n",
      "We cannot be satisfied as long as a colored person in Mississippi cannot vote and a colored person in New York believes he has nothing for which to vote.\n",
      "No, no we are not satisfied and we will not be satisfied until justice rolls down like waters and righteousness like a mighty stream.\n",
      "I am not unmindful that some of you have come here out of your trials and tribulations. Some of you have come from areas where your quest for freedom left you battered by storms of persecutions and staggered by the winds of police brutality.\n",
      "You have been the veterans of creative suffering. Continue to work with the faith that unearned suffering is redemptive.\n",
      "Go back to Mississippi, go back to Alabama, go back to South Carolina go back to Georgia, go back to Louisiana, go back to the slums and ghettos of our modern cities, knowing that somehow this situation can and will be changed.\n",
      "Let us not wallow in the valley of despair. I say to you, my friends, we have the difficulties of today and tomorrow.\n",
      "I still have a dream. It is a dream deeply rooted in the American dream.\n",
      "I have a dream that one day this nation will rise up and live out the true meaning of its creed. We hold these truths to be self-evident that all men are created equal.\n",
      "I have a dream that one day out in the red hills of Georgia the sons of former slaves and the sons of former slaveowners will be able to sit down together at the table of brotherhood.\n",
      "I have a dream that one day even the state of Mississippi, a state sweltering with the heat of oppression, will be transformed into an oasis of freedom and justice.\n",
      "I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by their character.\n",
      "I have a dream today.\n",
      "I have a dream that one day down in Alabama, with its vicious racists, with its governor having his lips dripping with the words of interposition and nullification; that one day right down in Alabama little black boys and black girls will be able to join hands with little white boys and white girls as sisters and brothers.\n",
      "I have a dream today.\n",
      " *-* \n",
      "I have a dream that one day every valley shall be engulfed, every hill shall be exalted and every mountain shall be made low, the rough places will be made plains and the crooked places will be made straight and the glory of the Lord shall be revealed and all flesh shall see it together.\n",
      "This is our hope. This is the faith that I will go back to the South with. With this faith we will be able to hew out of the mountain of despair a stone of hope.\n",
      "With this faith we will be able to transform the jangling discords of our nation into a beautiful symphony of brotherhood.\n",
      "With this faith we will be able to work together, to pray together, to struggle together, to go to jail together, to climb up for freedom together, knowing that we will be free one day.\n",
      "This will be the day when all of God’s children will be able to sing with new meaning “My country ’tis of thee, sweet land of liberty, of thee I sing. Land where my father’s died, land of the Pilgrim’s pride, from every mountainside, let freedom ring!”\n",
      "And if America is to be a great nation, this must become true. So let freedom ring from the hilltops of New Hampshire. Let freedom ring from the mighty mountains of New York.\n",
      " *-* \n",
      "Let freedom ring from the heightening Alleghenies of Pennsylvania.\n",
      " *-* \n",
      "Let freedom ring from the snow-capped Rockies of Colorado.\n",
      " *-* \n",
      "Let freedom ring from the curvaceous slopes of California.\n",
      "But not only that, let freedom, ring from Stone Mountain of Georgia.\n",
      " *-* \n",
      "Let freedom ring from every hill and molehill of Mississippi and every mountainside.\n",
      "When we let freedom ring, when we let it ring from every tenement and every hamlet, from every state and every city, we will be able to speed up that day when all of God’s children, black men and white men, Jews and Gentiles, Protestants and Catholics, will be able to join hands and sing in the words of the old spiritual, “Free at last, free at last. Thank God Almighty, we are free at last.”\n",
      "node_input: I am happy to join with you today in what will go down in history as the greatest demonstration for freedom in the history of our nation.\n",
      "Five score years ago, a great American, in whose symbolic shadow we stand today, signed the Emancipation Proclamation. This momentous decree came as a great beacon of hope to millions of slaves, who had been seared in the flames of whithering injustice. It came as a joyous daybreak to end the long night of their captivity. But one hundred years later, the colored America is still not free. One hundred years later, the life of the colored American is still sadly crippled by the manacle of segregation and the chains of discrimination.\n",
      "One hundred years later, the colored American lives on a lonely island of poverty in the midst of a vast ocean of material prosperity. One hundred years later, the colored American is still languishing in the corners of American society and finds himself an exile in his own land So we have come here today to dramatize a shameful condition.\n",
      "In a sense we have come to our Nation’s Capital to cash a check. When the architects of our great republic wrote the magnificent words of the Constitution and the Declaration of Independence, they were signing a promissory note to which every American was to fall heir.\n",
      "This note was a promise that all men, yes, black men as well as white men, would be guaranteed the inalienable rights of life liberty and the pursuit of happiness.\n",
      "It is obvious today that America has defaulted on this promissory note insofar as her citizens of color are concerned. Instead of honoring this sacred obligation, America has given its colored people a bad check, a check that has come back marked “insufficient funds.”\n",
      "But we refuse to believe that the bank of justice is bankrupt. We refuse to believe that there are insufficient funds in the great vaults of opportunity of this nation. So we have come to cash this check, a check that will give us upon demand the riches of freedom and security of justice.\n",
      "We have also come to his hallowed spot to remind America of the fierce urgency of Now. This is not time to engage in the luxury of cooling off or to take the tranquilizing drug of gradualism.\n",
      "Now is the time to make real the promise of democracy.\n",
      "Now it the time to rise from the dark and desolate valley of segregation to the sunlit path of racial justice.\n",
      "Now it the time to lift our nation from the quicksand of racial injustice to the solid rock of brotherhood.\n",
      "Now is the time to make justice a reality to all of God’s children.\n",
      "I would be fatal for the nation to overlook the urgency of the moment and to underestimate the determination of it’s colored citizens. This sweltering summer of the colored people’s legitimate discontent will not pass until there is an invigorating autumn of freedom and equality. Nineteen sixty-three is not an end but a beginning. Those who hope that the colored Americans needed to blow off steam and will now be content will have a rude awakening if the nation returns to business as usual.\n",
      "There will be neither rest nor tranquility in America until the colored citizen is granted his citizenship rights. The whirlwinds of revolt will continue to shake the foundations of our nation until the bright day of justice emerges.\n",
      "We can never be satisfied as long as our bodies, heavy with the fatigue of travel, cannot gain lodging in the motels of the highways and the hotels of the cities.\n",
      "We cannot be satisfied as long as the colored person’s basic mobility is from a smaller ghetto to a larger one.\n",
      "We can never be satisfied as long as our children are stripped of their selfhood and robbed of their dignity by signs stating “for white only.”\n",
      "We cannot be satisfied as long as a colored person in Mississippi cannot vote and a colored person in New York believes he has nothing for which to vote.\n",
      "No, no we are not satisfied and we will not be satisfied until justice rolls down like waters and righteousness like a mighty stream.\n",
      "I am not unmindful that some of you have come here out of your trials and tribulations. Some of you have come from areas where your quest for freedom left you battered by storms of persecutions and staggered by the winds of police brutality.\n",
      "You have been the veterans of creative suffering. Continue to work with the faith that unearned suffering is redemptive.\n",
      "Go back to Mississippi, go back to Alabama, go back to South Carolina go back to Georgia, go back to Louisiana, go back to the slums and ghettos of our modern cities, knowing that somehow this situation can and will be changed.\n",
      "Let us not wallow in the valley of despair. I say to you, my friends, we have the difficulties of today and tomorrow.\n",
      "I still have a dream. It is a dream deeply rooted in the American dream.\n",
      "I have a dream that one day this nation will rise up and live out the true meaning of its creed. We hold these truths to be self-evident that all men are created equal.\n",
      "I have a dream that one day out in the red hills of Georgia the sons of former slaves and the sons of former slaveowners will be able to sit down together at the table of brotherhood.\n",
      "I have a dream that one day even the state of Mississippi, a state sweltering with the heat of oppression, will be transformed into an oasis of freedom and justice.\n",
      "I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by their character.\n",
      "I have a dream today.\n",
      "I have a dream that one day down in Alabama, with its vicious racists, with its governor having his lips dripping with the words of interposition and nullification; that one day right down in Alabama little black boys and black girls will be able to join hands with little white boys and white girls as sisters and brothers.\n",
      "I have a dream today.\n",
      " *-* \n",
      "I have a dream that one day every valley shall be engulfed, every hill shall be exalted and every mountain shall be made low, the rough places will be made plains and the crooked places will be made straight and the glory of the Lord shall be revealed and all flesh shall see it together.\n",
      "This is our hope. This is the faith that I will go back to the South with. With this faith we will be able to hew out of the mountain of despair a stone of hope.\n",
      "With this faith we will be able to transform the jangling discords of our nation into a beautiful symphony of brotherhood.\n",
      "With this faith we will be able to work together, to pray together, to struggle together, to go to jail together, to climb up for freedom together, knowing that we will be free one day.\n",
      "This will be the day when all of God’s children will be able to sing with new meaning “My country ’tis of thee, sweet land of liberty, of thee I sing. Land where my father’s died, land of the Pilgrim’s pride, from every mountainside, let freedom ring!”\n",
      "And if America is to be a great nation, this must become true. So let freedom ring from the hilltops of New Hampshire. Let freedom ring from the mighty mountains of New York.\n",
      " *-* \n",
      "Let freedom ring from the heightening Alleghenies of Pennsylvania.\n",
      " *-* \n",
      "Let freedom ring from the snow-capped Rockies of Colorado.\n",
      " *-* \n",
      "Let freedom ring from the curvaceous slopes of California.\n",
      "But not only that, let freedom, ring from Stone Mountain of Georgia.\n",
      " *-* \n",
      "Let freedom ring from every hill and molehill of Mississippi and every mountainside.\n",
      "When we let freedom ring, when we let it ring from every tenement and every hamlet, from every state and every city, we will be able to speed up that day when all of God’s children, black men and white men, Jews and Gentiles, Protestants and Catholics, will be able to join hands and sing in the words of the old spiritual, “Free at last, free at last. Thank God Almighty, we are free at last.”\n",
      "node_output: \n",
      "In this excerpt from a speech, the speaker discusses the ongoing struggle for freedom and equality for African Americans, citing the Emancipation Proclamation and the promise of the Constitution. They call for immediate action and emphasize the urgency of the situation, stating that there can be no rest until justice is achieved. The speaker also shares their dream for a future where all races can coexist peacefully and where people are judged by their character rather than the color of their skin.\n",
      "Error decoding JSON in node_input: I am happy to join with you today in what will go down in history as the greatest demonstration for freedom in the history of our nation.\n",
      "Five score years ago, a great American, in whose symbolic shadow we stand today, signed the Emancipation Proclamation. This momentous decree came as a great beacon of hope to millions of slaves, who had been seared in the flames of whithering injustice. It came as a joyous daybreak to end the long night of their captivity. But one hundred years later, the colored America is still not free. One hundred years later, the life of the colored American is still sadly crippled by the manacle of segregation and the chains of discrimination.\n",
      "One hundred years later, the colored American lives on a lonely island of poverty in the midst of a vast ocean of material prosperity. One hundred years later, the colored American is still languishing in the corners of American society and finds himself an exile in his own land So we have come here today to dramatize a shameful condition.\n",
      "In a sense we have come to our Nation’s Capital to cash a check. When the architects of our great republic wrote the magnificent words of the Constitution and the Declaration of Independence, they were signing a promissory note to which every American was to fall heir.\n",
      "This note was a promise that all men, yes, black men as well as white men, would be guaranteed the inalienable rights of life liberty and the pursuit of happiness.\n",
      "It is obvious today that America has defaulted on this promissory note insofar as her citizens of color are concerned. Instead of honoring this sacred obligation, America has given its colored people a bad check, a check that has come back marked “insufficient funds.”\n",
      "But we refuse to believe that the bank of justice is bankrupt. We refuse to believe that there are insufficient funds in the great vaults of opportunity of this nation. So we have come to cash this check, a check that will give us upon demand the riches of freedom and security of justice.\n",
      "We have also come to his hallowed spot to remind America of the fierce urgency of Now. This is not time to engage in the luxury of cooling off or to take the tranquilizing drug of gradualism.\n",
      "Now is the time to make real the promise of democracy.\n",
      "Now it the time to rise from the dark and desolate valley of segregation to the sunlit path of racial justice.\n",
      "Now it the time to lift our nation from the quicksand of racial injustice to the solid rock of brotherhood.\n",
      "Now is the time to make justice a reality to all of God’s children.\n",
      "I would be fatal for the nation to overlook the urgency of the moment and to underestimate the determination of it’s colored citizens. This sweltering summer of the colored people’s legitimate discontent will not pass until there is an invigorating autumn of freedom and equality. Nineteen sixty-three is not an end but a beginning. Those who hope that the colored Americans needed to blow off steam and will now be content will have a rude awakening if the nation returns to business as usual.\n",
      "There will be neither rest nor tranquility in America until the colored citizen is granted his citizenship rights. The whirlwinds of revolt will continue to shake the foundations of our nation until the bright day of justice emerges.\n",
      "We can never be satisfied as long as our bodies, heavy with the fatigue of travel, cannot gain lodging in the motels of the highways and the hotels of the cities.\n",
      "We cannot be satisfied as long as the colored person’s basic mobility is from a smaller ghetto to a larger one.\n",
      "We can never be satisfied as long as our children are stripped of their selfhood and robbed of their dignity by signs stating “for white only.”\n",
      "We cannot be satisfied as long as a colored person in Mississippi cannot vote and a colored person in New York believes he has nothing for which to vote.\n",
      "No, no we are not satisfied and we will not be satisfied until justice rolls down like waters and righteousness like a mighty stream.\n",
      "I am not unmindful that some of you have come here out of your trials and tribulations. Some of you have come from areas where your quest for freedom left you battered by storms of persecutions and staggered by the winds of police brutality.\n",
      "You have been the veterans of creative suffering. Continue to work with the faith that unearned suffering is redemptive.\n",
      "Go back to Mississippi, go back to Alabama, go back to South Carolina go back to Georgia, go back to Louisiana, go back to the slums and ghettos of our modern cities, knowing that somehow this situation can and will be changed.\n",
      "Let us not wallow in the valley of despair. I say to you, my friends, we have the difficulties of today and tomorrow.\n",
      "I still have a dream. It is a dream deeply rooted in the American dream.\n",
      "I have a dream that one day this nation will rise up and live out the true meaning of its creed. We hold these truths to be self-evident that all men are created equal.\n",
      "I have a dream that one day out in the red hills of Georgia the sons of former slaves and the sons of former slaveowners will be able to sit down together at the table of brotherhood.\n",
      "I have a dream that one day even the state of Mississippi, a state sweltering with the heat of oppression, will be transformed into an oasis of freedom and justice.\n",
      "I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by their character.\n",
      "I have a dream today.\n",
      "I have a dream that one day down in Alabama, with its vicious racists, with its governor having his lips dripping with the words of interposition and nullification; that one day right down in Alabama little black boys and black girls will be able to join hands with little white boys and white girls as sisters and brothers.\n",
      "I have a dream today.\n",
      " *-* \n",
      "I have a dream that one day every valley shall be engulfed, every hill shall be exalted and every mountain shall be made low, the rough places will be made plains and the crooked places will be made straight and the glory of the Lord shall be revealed and all flesh shall see it together.\n",
      "This is our hope. This is the faith that I will go back to the South with. With this faith we will be able to hew out of the mountain of despair a stone of hope.\n",
      "With this faith we will be able to transform the jangling discords of our nation into a beautiful symphony of brotherhood.\n",
      "With this faith we will be able to work together, to pray together, to struggle together, to go to jail together, to climb up for freedom together, knowing that we will be free one day.\n",
      "This will be the day when all of God’s children will be able to sing with new meaning “My country ’tis of thee, sweet land of liberty, of thee I sing. Land where my father’s died, land of the Pilgrim’s pride, from every mountainside, let freedom ring!”\n",
      "And if America is to be a great nation, this must become true. So let freedom ring from the hilltops of New Hampshire. Let freedom ring from the mighty mountains of New York.\n",
      " *-* \n",
      "Let freedom ring from the heightening Alleghenies of Pennsylvania.\n",
      " *-* \n",
      "Let freedom ring from the snow-capped Rockies of Colorado.\n",
      " *-* \n",
      "Let freedom ring from the curvaceous slopes of California.\n",
      "But not only that, let freedom, ring from Stone Mountain of Georgia.\n",
      " *-* \n",
      "Let freedom ring from every hill and molehill of Mississippi and every mountainside.\n",
      "When we let freedom ring, when we let it ring from every tenement and every hamlet, from every state and every city, we will be able to speed up that day when all of God’s children, black men and white men, Jews and Gentiles, Protestants and Catholics, will be able to join hands and sing in the words of the old spiritual, “Free at last, free at last. Thank God Almighty, we are free at last.”\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import time\n",
    "import json\n",
    "import promptquality as pq\n",
    "\n",
    "def rouge_executor(row) -> float:\n",
    "    try:\n",
    "        print(f\"node_input: {row.node_input}\")\n",
    "        print(f\"node_output: {row.node_output}\")\n",
    "\n",
    "        # Try to decode node_input as JSON\n",
    "        try:\n",
    "            node_input = json.loads(row.node_input)\n",
    "            reference = node_input.get(\"content\", \"\").strip()\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON in node_input: {row.node_input}\")\n",
    "            return 0.0\n",
    "\n",
    "        # Try to decode node_output as JSON\n",
    "        try:\n",
    "            node_output = json.loads(row.node_output)\n",
    "            prediction = node_output.get(\"content\", \"\").strip()\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON in node_output: {row.node_output}\")\n",
    "            return 0.0\n",
    "\n",
    "        if not reference or not prediction:\n",
    "            print(\"'content' fields are empty in node_input or node_output\")\n",
    "            return 0.0\n",
    "\n",
    "        # Calculates ROUGE-L\n",
    "        rouge = evaluate.load(\"rouge\")\n",
    "        rouge_values = rouge.compute(predictions=[prediction], references=[reference])\n",
    "\n",
    "        return rouge_values.get(\"rougeL\", 0.0)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error in rouge_executor: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def rouge_aggregator(scores, indices) -> dict:\n",
    "    if len(scores) == 0:\n",
    "        return {'Average RougeL': 0.0}\n",
    "    else:\n",
    "        return {'Average RougeL': sum(scores) / len(scores)}\n",
    "\n",
    "# Define CustomScorer with corrected functions\n",
    "rouge_scorer = pq.CustomScorer(name='RougeL', executor=rouge_executor, aggregator=rouge_aggregator)\n",
    "\n",
    "# Invoke the chain to get the summaries\n",
    "print(\"Invoking the chain...\")\n",
    "response = chain.invoke(chunks)\n",
    "\n",
    "# Debugging to check the content of response\n",
    "print(f\"Response returned by the chain: {response}\")\n",
    "\n",
    "# Configures the assessment execution\n",
    "partitioned_run = pq.EvaluateRun(\n",
    "    project_name=\"AIStudio_template_code_summarization\",\n",
    "    run_name=\"Test4 partitioned script\",\n",
    "    scorers=[pq.Scorers.toxicity, pq.Scorers.sexist, rouge_scorer]\n",
    ")\n",
    "\n",
    "# Measures execution time\n",
    "start_time = time.time()\n",
    "response = chain.invoke(chunks)\n",
    "total_time = int((time.time() - start_time) * 1000000)\n",
    "\n",
    "# Adiciona os dados ao workflow\n",
    "partitioned_run.add_workflow(input=chunks, output=response, duration_ns=total_time) \n",
    "partitioned_run.add_llm_step(input=chunks, output=response, duration_ns=total_time, model='local')\n",
    "\n",
    "# Finalizes the execution of the assessment\n",
    "partitioned_run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf5bff8-fb62-433e-b1ff-985e610fe4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS CODE IS NOT WORKING YET, AS GALILEO DOES NOT SUPPORT LISTS AS THE OUTPUT OF CHAIN NODES \n",
    "\n",
    "#summarization_callback =  pq.GalileoPromptCallback(\n",
    "#    project_name = \"AIStudio_summarization_template\",\n",
    "#    run_name = \"Partitioned transcript\",\n",
    "#    scorers=[pq.Scorers.toxicity, pq.Scorers.sexist, rouge_scorer]\n",
    "#)\n",
    "\n",
    "#summaries = chain.invoke(chunks, config={\"callbacks\": [summarization_callback]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02e043a-4d8a-47ba-83b2-d99c0d803575",
   "metadata": {},
   "source": [
    "## Galileo Protect\n",
    "\n",
    "Galileo Protect serves as a powerful tool for safeguarding AI model outputs by detecting and preventing the release of sensitive information like personal addresses or other PII. By integrating Galileo Protect into your AI pipelines, you can ensure that model responses comply with privacy and security guidelines in real-time.\n",
    "\n",
    "Galileo functions as an API that provides support for protection verification of your chain/LLM. To log into the Galileo console, it is necessary to integrate it with another service, such as Galileo Evaluate or Galileo Observe.\n",
    "\n",
    "**Attention**: an integrated API within the Galileo console is required to perform this verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0a39a4c-6a04-4510-9c10-4b281566d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import galileo_protect as gp\n",
    "from galileo_protect import ProtectTool, ProtectParser, Ruleset\n",
    "\n",
    "with open(\"secrets.yaml\", \"r\") as file:\n",
    "    secrets = yaml.safe_load(file)\n",
    "\n",
    "# 2. Configure environment variables with credentials\n",
    "os.environ[\"GALILEO_API_KEY\"] = secrets[\"Galileo\"]\n",
    "os.environ[\"GALILEO_CONSOLE_URL\"] = secrets.get(\"galileo_url\", \"https://console.hp.galileocloud.io/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc23d0eb-806a-4a47-b051-f45ba2466801",
   "metadata": {},
   "source": [
    "Galileo Protect works by creating rules that identify conditions such as Personally Identifiable Information (PII) and toxicity. It ensures that the prompt will not receive or respond to sensitive questions. In this example, we create a set of rules (ruleset) and a set of actions that return a pre-programmed response if a rule is triggered. Galileo Protect also offers a variety of other metrics to suit different protection needs. You can learn more about the available metrics here: [Supported Metrics and Operators](https://docs.rungalileo.io/galileo/gen-ai-studio-products/galileo-protect/how-to/supported-metrics-and-operators).\n",
    "\n",
    "Additionally, it is possible to import rulesets directly from Galileo through stages. Learn more about this feature here: [Invoking Rulesets](https://docs.rungalileo.io/galileo/gen-ai-studio-products/galileo-protect/how-to/invoking-rulesets).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23894954-93b0-4c06-9a2c-e3323fcaa3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project created. Project ID: 1b54bd2a-8e0f-4e18-9472-0841c74e4641\n",
      "Stage created. ID do stage: 36a85923-8cc4-461b-a164-72a74f04301f\n",
      "Invoking the chain with PII protection...\n",
      "Protected chain response:\n",
      "Personal Identifiable Information detected. Sorry, I cannot provide the response.\n"
     ]
    }
   ],
   "source": [
    "project = gp.create_project(\"validate_protect\")\n",
    "print(f\"Project created. Project ID: {project.id}\")\n",
    "\n",
    "stage = gp.create_stage(name=\"validate_chain_stage\", project_id=project.id)\n",
    "print(f\"Stage created. ID do stage: {stage.id}\")\n",
    "\n",
    "# Define the Ruleset for PII Protection\n",
    "ruleset = Ruleset(\n",
    "    rules=[\n",
    "        {\n",
    "            \"metric\": \"pii\",\n",
    "            \"operator\": \"contains\",\n",
    "            \"target_value\": \"ssn\",\n",
    "        },\n",
    "    ],\n",
    "    action={\n",
    "        \"type\": \"OVERRIDE\",\n",
    "        \"choices\": [\"Personal Identifiable Information detected. Sorry, I cannot provide the response.\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Initialize ProtectTool with the configured stage_id and ruleset\n",
    "protect_tool = ProtectTool(stage_id=stage.id, prioritized_rulesets=[ruleset], timeout=10)\n",
    "\n",
    "# Use existing chain and combine with ProtectTool\n",
    "protect_parser = ProtectParser(chain=chain)  # 'chain' has already been defined previously\n",
    "protected_chain = protect_tool | protect_parser.parser\n",
    "\n",
    "# Example of using the protected chain with input and output\n",
    "input_data = {\n",
    "    \"input\": \"John Doe's social security number is 123-45-6789.\",\n",
    "    \"output\": \"John Doe's social security number is 123-45-6789.\"\n",
    "}\n",
    "\n",
    "# Invoke the protected chain\n",
    "print(\"Invoking the chain with PII protection...\")\n",
    "response = protected_chain.invoke(input_data)\n",
    "print(\"Protected chain response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6563e41c-c1a9-423e-a11f-5e7c6ac53770",
   "metadata": {},
   "source": [
    "## Galileo Observe\n",
    "\n",
    "Galileo Observe helps you monitor your generative AI applications in production. With Observe you will understand how your users are using your application and identify where things are going wrong. Keep tabs on your production system, instantly receive alerts when bad things happen, and perform deep root cause analysis though the Observe dashboard.\n",
    "\n",
    "You can connect Galileo Observe to your Langchain chain to monitor metrics such as cost and guardrail indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "418cbf0e-6c9d-4120-b9e3-17b376b3b08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking the chain with Galileo Observe...\n",
      "Observed chain output:\n",
      "\n",
      "The excerpt asks for a story about technology and innovation, an explanation of how artificial intelligence is shaping the future, and a summary of the impact of renewable energy on society. This suggests a focus on the intersection of technology and progress, and how advancements such as artificial intelligence and renewable energy are shaping our future and society as a whole.\n"
     ]
    }
   ],
   "source": [
    "from galileo_observe import GalileoObserveCallback\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "example_query = \"\"\"Tell me a story about technology and innovation. \n",
    "Explain how artificial intelligence is shaping the future. \n",
    "Summarize the impact of renewable energy on society.\"\"\"\n",
    "\n",
    "result_break = lambda_break.invoke(example_query)\n",
    "\n",
    "\n",
    "chain = lambda_break | {\n",
    "    f\"summary_{i}\": itemgetter(i) | prompt | llm\n",
    "    for i in range(len(result_break))\n",
    "} | lambda_join | StrOutputParser()\n",
    "\n",
    "monitor_handler = GalileoObserveCallback(project_name=\"validate_galileo_observe\")\n",
    "\n",
    "print(\"Invoking the chain with Galileo Observe...\")\n",
    "try:\n",
    "    output = chain.invoke(\n",
    "        example_query,\n",
    "        config={\"callbacks\": [monitor_handler]}\n",
    "    )\n",
    "    print(\"Observed chain output:\")\n",
    "    print(output)\n",
    "except Exception as e:\n",
    "    print(f\"Error during chain execution: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2910bddc-a194-4011-b82d-3a8cd6ea762d",
   "metadata": {},
   "source": [
    "## Model service Galileo Protect + Observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1f6721be-3298-4dfc-91dd-4b2bf27007d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing experiment in MLflow.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4e1d5e700a45afa34c4825274fda94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e013d88a7d944b5947d897e8f03ee63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'Text_Summarization_Service_Model' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered model with execution ID: fc1ae4565c524db9b15cb8309357762b\n",
      "Model registered successfully. Run ID: fc1ae4565c524db9b15cb8309357762b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '19' of model 'Text_Summarization_Service_Model'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from mlflow.pyfunc import PythonModel, ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from galileo_observe import GalileoObserveCallback\n",
    "from galileo_protect import ProtectTool, ProtectParser, Ruleset\n",
    "import galileo_protect as gp\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "from langchain_community.llms import LlamaCpp\n",
    "\n",
    "\n",
    "class SemanticSplitter:\n",
    "    def __init__(self, content, embedding_model, method=\"number\", partition_count=10, quantile=0.9):\n",
    "        print(\"Starting SemanticSplitter...\")\n",
    "        self.content = [line.strip() for line in content if line.strip()]  \n",
    "        self.embedding_model = embedding_model\n",
    "        self.partition_count = partition_count\n",
    "        self.quantile = quantile\n",
    "\n",
    "        print(\"Calculating embeddings for content...\")\n",
    "        self.embeddings = embedding_model.encode(self.content)\n",
    "        self.distances = [cosine(self.embeddings[i - 1], self.embeddings[i]) for i in range(1, len(self.embeddings))]\n",
    "        self.breaks = []\n",
    "        self.load_breaks(method=method)\n",
    "        print(f\"Loaded breaks: {self.breaks}\")\n",
    "\n",
    "    def load_breaks(self, method='number'):\n",
    "        print(f\"Loading breaks using the method: {method}\")\n",
    "        if len(self.distances) == 0:\n",
    "            print(\"No distances calculated. No breaks loaded.\")\n",
    "            return\n",
    "\n",
    "        if method == 'number':\n",
    "            if self.partition_count > len(self.distances):\n",
    "                self.partition_count = len(self.distances)\n",
    "            self.breaks = np.sort(np.argpartition(self.distances, self.partition_count - 1)[:self.partition_count - 1])\n",
    "        elif method == 'quantiles':\n",
    "            threshold = np.quantile(self.distances, self.quantile)\n",
    "            self.breaks = [i for i, v in enumerate(self.distances) if v >= threshold]\n",
    "\n",
    "    def get_chunk(self, beginning, end):\n",
    "        return '\\n'.join(self.content[beginning:end]).strip()\n",
    "\n",
    "    def get_chunks(self):\n",
    "        print(\"Dividing text into chunks...\")\n",
    "        if len(self.breaks) == 0:\n",
    "            return [self.get_chunk(0, len(self.content))]\n",
    "\n",
    "        chunks = []\n",
    "        beginning = 0\n",
    "        for break_position in self.breaks:\n",
    "            chunk = self.get_chunk(beginning, break_position + 1)\n",
    "            if chunk:\n",
    "                chunks.append(chunk)\n",
    "            beginning = break_position + 1\n",
    "\n",
    "        chunk = self.get_chunk(beginning, len(self.content))\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "\n",
    "        print(f\"Chunks gerados: {chunks}\")\n",
    "        return chunks\n",
    "\n",
    "class TextSummarizationService(PythonModel):\n",
    "    def load_context(self, context):\n",
    "        print(\"Loading model context.\")\n",
    "\n",
    "        \n",
    "        secrets_path = context.artifacts[\"secrets\"]\n",
    "        with open(secrets_path, \"r\") as file:\n",
    "            secrets = yaml.safe_load(file)\n",
    "\n",
    "        \n",
    "        os.environ[\"OPENAI_API_KEY\"] = secrets.get(\"OpenAI\", \"\")\n",
    "        os.environ[\"GALILEO_API_KEY\"] = secrets.get(\"Galileo\", \"\")\n",
    "        os.environ[\"GALILEO_CONSOLE_URL\"] = secrets.get(\"galileo_url\", \"https://console.hp.galileocloud.io/\")\n",
    "\n",
    "        \n",
    "        model_source = secrets.get(\"source\", \"HuggingFace\") #Use 'OpenAI', 'HuggingFace', or 'local_model'.\n",
    "\n",
    "        \n",
    "        if model_source == \"OpenAI\":\n",
    "            os.environ[\"OPENAI_API_KEY\"] = secrets.get(\"OpenAI\", \"\")\n",
    "            self.llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\")\n",
    "            print(\"Using the OpenAI model.\")\n",
    "        elif model_source == \"HuggingFace\":\n",
    "            huggingface_key = secrets.get(\"HuggingFace\", \"\")\n",
    "            hf_model_repo = secrets.get(\"hf_model_repo\", \"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "            self.llm = HuggingFaceEndpoint(huggingfacehub_api_token=huggingface_key, repo_id=hf_model_repo)\n",
    "            print(\"Using the HuggingFace model.\")\n",
    "        elif model_config[\"source\"] == \"local_model\":\n",
    "            print(\"[INFO] Initializing local LlamaCpp model.\")\n",
    "            callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "            self.llm = LlamaCpp(\n",
    "                model_path=model_config[\"local_model_path\"],\n",
    "                n_gpu_layers=30,\n",
    "                n_batch=512,\n",
    "                n_ctx=4096,\n",
    "                max_tokens=1024,\n",
    "                f16_kv=True,\n",
    "                callback_manager=callback_manager,\n",
    "                verbose=False,\n",
    "                stop=[],\n",
    "                streaming=False,\n",
    "                temperature=0.2,\n",
    "            )\n",
    "            print(\"Using the local LlamaCpp model.\")\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model source. Use 'OpenAI', 'HuggingFace', or 'local_model'.\")\n",
    "\n",
    "        \n",
    "        self.observe_callback = GalileoObserveCallback(project_name=\"summarization_service_observe\")\n",
    "\n",
    "        \n",
    "        self.prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        The following text is an excerpt of a transcription:\n",
    "\n",
    "        ###\n",
    "        {context}\n",
    "        ###\n",
    "\n",
    "        Please, produce a single paragraph summarizing the given excerpt.\n",
    "        \"\"\")\n",
    "\n",
    "        project = gp.create_project(\"summarization_service_protect\")\n",
    "        print(f\"Project created. Project ID: {project.id}\")\n",
    "\n",
    "        stage = gp.create_stage(name=\"summarization_stage\", project_id=project.id)\n",
    "        print(f\"Stage created. Stage ID: {stage.id}\")\n",
    "\n",
    "        ruleset = Ruleset(\n",
    "            rules=[\n",
    "                {\n",
    "                    \"metric\": \"pii\",\n",
    "                    \"operator\": \"contains\",\n",
    "                    \"target_value\": \"ssn\",\n",
    "                },\n",
    "            ],\n",
    "            action={\n",
    "                \"type\": \"OVERRIDE\",\n",
    "                \"choices\": [\"Personal Identifiable Information detected. Sorry, I cannot provide the summary.\"]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        protect_tool = ProtectTool(stage_id=stage.id, prioritized_rulesets=[ruleset], timeout=10)\n",
    "        self.protect_parser = ProtectParser(chain=self.prompt | self.llm | StrOutputParser())\n",
    "        self.protected_chain = protect_tool | self.protect_parser.parser\n",
    "\n",
    "        self.embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        text = model_input[\"text\"].iloc[0]\n",
    "        print(f\"Input text:\\n{text[:200]}...\")  \n",
    "\n",
    "        splitter = SemanticSplitter(text.split(\"\\n\"), self.embedding_model, method=\"number\", partition_count=6)\n",
    "        chunks = splitter.get_chunks()\n",
    "\n",
    "        print(f\"Number of chunks generated:{len(chunks)}\")\n",
    "\n",
    "        combined_input = \"\\n\\n\".join(chunks)\n",
    "        print(f\"Combined text for batch:\\n{combined_input[:500]}...\")  # Show first 500 characters\n",
    "\n",
    "        print(\"Sending all chunks in batch to the chain...\")\n",
    "        try:\n",
    "            result = self.protected_chain.invoke(\n",
    "                {\"input\": combined_input, \"output\": \"\"},\n",
    "                config={\"callbacks\": [self.observe_callback]}\n",
    "            )\n",
    "            print(\"Batch result processed successfully.\")\n",
    "        except Exception as e:\n",
    "            result = f\"Error processing batch:{e}\"\n",
    "            print(result)\n",
    "\n",
    "        print(f\"Processing completed. Total chunks processed: {len(chunks)}\")\n",
    "\n",
    "        return pd.DataFrame([{\"summary\": result}])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Initializing experiment in MLflow.\")\n",
    "\n",
    "    mlflow.set_experiment(\"Text_Summarization_Service\")\n",
    "\n",
    "    secrets_path = \"secrets.yaml\"\n",
    "    model_path = \"/home/jovyan/datafabric/Llama_7b/ggml-model-f16-Q5_K_M.gguf\"\n",
    "\n",
    "    if not os.path.exists(secrets_path):\n",
    "        raise FileNotFoundError(f\"secrets.yaml file not found in path: {os.path.abspath(secrets_path)}\")\n",
    "\n",
    "    input_schema = Schema([ColSpec(\"string\", \"text\")])\n",
    "    output_schema = Schema([ColSpec(\"string\", \"summary\")])\n",
    "    signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "    with mlflow.start_run(run_name=\"Text_Summarization_Service_Run\") as run:\n",
    "        mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"text_summarization_service\",\n",
    "            python_model=TextSummarizationService(),\n",
    "            artifacts={\"secrets\": secrets_path, \"model_folder\": model_path},\n",
    "            signature=signature,\n",
    "            pip_requirements=[\n",
    "                \"galileo-protect==0.15.1\",\n",
    "                \"galileo-observe==1.13.2\",\n",
    "                \"pyyaml\",\n",
    "                \"pandas\",\n",
    "                \"sentence-transformers\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        model_uri = f\"runs:/{run.info.run_id}/text_summarization_service\"\n",
    "        mlflow.register_model(model_uri=model_uri, name=\"Text_Summarization_Service_Model\")\n",
    "\n",
    "        print(f\"Registered model with execution ID: {run.info.run_id}\")\n",
    "        print(f\"Model registered successfully. Run ID: {run.info.run_id}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
